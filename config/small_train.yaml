prepare_data:
  clip_audio_secs: 4
  in_op_threads: true
  limit_rows: 100
  shards: 4
  map_workers: 2
  prepared_data: small_data

model:
  name: small_train.model
  encoder:
    n_layer: 6
    n_head: 6
    n_embd: 384
    attn_pdrop: 0.2
  decoder:
    n_layer: 6
    n_head: 6
    n_embd: 384
    attn_pdrop: 0.2
    seq_length: 600 # 4 * 75 * 2

training:
  args:
    per_device_train_batch_size: 8
    per_device_eval_batch_size: 4
    eval_accumulation_steps: 4
    num_train_epochs: 10
    weight_decay: 0.01
    learning_rate: 2.0e-5